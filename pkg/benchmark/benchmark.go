package benchmark

import (
	"context"
	"crypto/tls"
	"fmt"
	"io"
	"net/http"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/quic-go/quic-go/http3"
	"golang.org/x/net/http2"

	"httpbench/pkg/config"
	"httpbench/pkg/stats"
	"httpbench/pkg/template"
	"httpbench/pkg/validator"
)

// Benchmark åŸºå‡†æµ‹è¯•å™¨
type Benchmark struct {
	config    *config.Config
	client    *http.Client
	stats     *stats.Collector
	validator *validator.Validator
	template  *template.Engine

	// çŠ¶æ€ç®¡ç†
	running   atomic.Bool
	startTime time.Time

	// é€Ÿç‡é™åˆ¶
	rateLimiter *RateLimiter
}

// Results æµ‹è¯•ç»“æœ
type Results struct {
	TotalRequests   int64
	SuccessRequests int64
	FailedRequests  int64

	Duration   time.Duration
	Throughput float64

	BytesReceived int64
	BytesSent     int64

	Latency      stats.LatencyStats
	ErrorsByType map[string]int64
	StatusCodes  map[int]int64

	// æ—¶é—´åºåˆ—æ•°æ®
	TimeSeries []stats.TimePoint
}

// New åˆ›å»ºåŸºå‡†æµ‹è¯•å™¨
func New(cfg *config.Config) (*Benchmark, error) {
	// åˆ›å»ºHTTPå®¢æˆ·ç«¯
	client, err := createHTTPClient(cfg)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºHTTPå®¢æˆ·ç«¯å¤±è´¥: %w", err)
	}

	// åˆ›å»ºç»Ÿè®¡æ”¶é›†å™¨
	statsCollector := stats.NewCollector()

	// åˆ›å»ºéªŒè¯å™¨
	val := validator.New(cfg.Validation)

	// åˆ›å»ºæ¨¡æ¿å¼•æ“
	tmpl := template.New(cfg.Request.Template)

	b := &Benchmark{
		config:    cfg,
		client:    client,
		stats:     statsCollector,
		validator: val,
		template:  tmpl,
	}

	// åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨
	if cfg.Load.RateLimit > 0 {
		b.rateLimiter = NewRateLimiter(cfg.Load.RateLimit)
	}

	return b, nil
}

// Run æ‰§è¡ŒåŸºå‡†æµ‹è¯•
func (b *Benchmark) Run(ctx context.Context) (*Results, error) {
	b.running.Store(true)
	b.startTime = time.Now()
	defer b.running.Store(false)

	// åˆ›å»ºå·¥ä½œä¸Šä¸‹æ–‡
	workCtx, cancel := context.WithCancel(ctx)
	defer cancel()

	// æ ¹æ®è´Ÿè½½æ¨¡å¼æ‰§è¡Œæµ‹è¯•
	switch b.config.Load.LoadPattern {
	case config.LoadPatternRampUp:
		return b.runRampUp(workCtx)
	case config.LoadPatternBurst:
		return b.runBurst(workCtx)
	default:
		return b.runConstant(workCtx)
	}
}

// runConstant æ’å®šè´Ÿè½½æµ‹è¯•
func (b *Benchmark) runConstant(ctx context.Context) (*Results, error) {
	var wg sync.WaitGroup
	requestChan := make(chan struct{}, b.config.Load.Concurrency)

	// æ—¶é—´æˆ–è¯·æ±‚æ•°é™åˆ¶
	var timeoutCtx context.Context
	var timeoutCancel context.CancelFunc

	if b.config.Load.Duration > 0 {
		timeoutCtx, timeoutCancel = context.WithTimeout(ctx, b.config.Load.Duration)
	} else {
		timeoutCtx, timeoutCancel = context.WithCancel(ctx)
	}
	defer timeoutCancel()

	// å¯åŠ¨å·¥ä½œåç¨‹
	for i := 0; i < b.config.Load.Concurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			b.worker(timeoutCtx, workerID, requestChan)
		}(i)
	}

	// ç”Ÿæˆè¯·æ±‚
	go b.generateRequests(timeoutCtx, requestChan)

	// å®æ—¶ç›‘æ§
	if b.config.Output.RealtimeMonitor {
		go b.realtimeMonitor(timeoutCtx)
	}

	// ç­‰å¾…å®Œæˆ
	wg.Wait()

	return b.generateResults(), nil
}

// runRampUp æ¸è¿›å¼è´Ÿè½½æµ‹è¯•
func (b *Benchmark) runRampUp(ctx context.Context) (*Results, error) {
	rampCfg := b.config.Load.RampUp
	if !rampCfg.Enabled {
		return b.runConstant(ctx)
	}

	stepDuration := rampCfg.Duration / time.Duration(rampCfg.Steps)
	concurrencyStep := (rampCfg.EndConcurrency - rampCfg.StartConcurrency) / rampCfg.Steps

	fmt.Printf("ğŸ“ˆ æ¸è¿›å¼è´Ÿè½½: %d -> %d (æ­¥é•¿: %d, æ¯æ­¥: %v)\n",
		rampCfg.StartConcurrency, rampCfg.EndConcurrency, rampCfg.Steps, stepDuration)

	var wg sync.WaitGroup
	requestChan := make(chan struct{}, rampCfg.EndConcurrency)
	workerControl := make(chan int, rampCfg.EndConcurrency)

	// å¯åŠ¨å·¥ä½œåç¨‹æ± 
	for i := 0; i < rampCfg.EndConcurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			// ç­‰å¾…æ¿€æ´»ä¿¡å·
			<-workerControl
			b.worker(ctx, workerID, requestChan)
		}(i)
	}

	// æ¸è¿›å¢åŠ å¹¶å‘
	go func() {
		currentConcurrency := rampCfg.StartConcurrency

		// æ¿€æ´»åˆå§‹å·¥ä½œåç¨‹
		for i := 0; i < currentConcurrency; i++ {
			workerControl <- i
		}

		ticker := time.NewTicker(stepDuration)
		defer ticker.Stop()

		for step := 0; step < rampCfg.Steps && ctx.Err() == nil; step++ {
			<-ticker.C

			// å¢åŠ å¹¶å‘
			newConcurrency := currentConcurrency + concurrencyStep
			if newConcurrency > rampCfg.EndConcurrency {
				newConcurrency = rampCfg.EndConcurrency
			}

			for i := currentConcurrency; i < newConcurrency; i++ {
				workerControl <- i
			}

			fmt.Printf("  â†‘ å¹¶å‘è°ƒæ•´: %d -> %d\n", currentConcurrency, newConcurrency)
			currentConcurrency = newConcurrency
		}
	}()

	// ç”Ÿæˆè¯·æ±‚
	go b.generateRequests(ctx, requestChan)

	// å®æ—¶ç›‘æ§
	if b.config.Output.RealtimeMonitor {
		go b.realtimeMonitor(ctx)
	}

	wg.Wait()
	return b.generateResults(), nil
}

// runBurst çªå‘è´Ÿè½½æµ‹è¯•
func (b *Benchmark) runBurst(ctx context.Context) (*Results, error) {
	burstCfg := b.config.Load.BurstMode
	if !burstCfg.Enabled {
		return b.runConstant(ctx)
	}

	fmt.Printf("ğŸ’¥ çªå‘è´Ÿè½½æ¨¡å¼: åŸºå‡† %d, çªå‘ %d (æŒç»­: %v, é—´éš”: %v)\n",
		burstCfg.BaseConcurrency, burstCfg.BurstConcurrency,
		burstCfg.BurstDuration, burstCfg.BurstInterval)

	var wg sync.WaitGroup
	requestChan := make(chan struct{}, burstCfg.BurstConcurrency)

	// å¯åŠ¨åŸºå‡†å·¥ä½œåç¨‹
	for i := 0; i < burstCfg.BaseConcurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			b.worker(ctx, workerID, requestChan)
		}(i)
	}

	// çªå‘åç¨‹æ± 
	// burstWorkers := make(chan struct{}, burstCfg.BurstConcurrency-burstCfg.BaseConcurrency)

	// çªå‘æ§åˆ¶
	go func() {
		ticker := time.NewTicker(burstCfg.BurstInterval)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				// è§¦å‘çªå‘
				fmt.Printf("  ğŸ’¥ è§¦å‘çªå‘: +%d å¹¶å‘\n", burstCfg.BurstConcurrency-burstCfg.BaseConcurrency)

				burstCtx, burstCancel := context.WithTimeout(ctx, burstCfg.BurstDuration)

				for i := 0; i < burstCfg.BurstConcurrency-burstCfg.BaseConcurrency; i++ {
					wg.Add(1)
					go func(workerID int) {
						defer wg.Done()
						b.worker(burstCtx, burstCfg.BaseConcurrency+workerID, requestChan)
					}(i)
				}

				<-burstCtx.Done()
				burstCancel()
				fmt.Printf("  âœ“ çªå‘ç»“æŸ\n")
			}
		}
	}()

	// ç”Ÿæˆè¯·æ±‚
	go b.generateRequests(ctx, requestChan)

	// å®æ—¶ç›‘æ§
	if b.config.Output.RealtimeMonitor {
		go b.realtimeMonitor(ctx)
	}

	wg.Wait()
	return b.generateResults(), nil
}

// worker å·¥ä½œåç¨‹
func (b *Benchmark) worker(ctx context.Context, workerID int, requestChan <-chan struct{}) {
	for {
		select {
		case <-ctx.Done():
			return
		case _, ok := <-requestChan:
			if !ok {
				return
			}
			b.executeRequest(ctx, workerID)
		}
	}
}

// generateRequests ç”Ÿæˆè¯·æ±‚
func (b *Benchmark) generateRequests(ctx context.Context, requestChan chan<- struct{}) {
	defer close(requestChan)

	totalRequests := b.config.Load.TotalRequests
	requestCount := int64(0)

	for {
		select {
		case <-ctx.Done():
			return
		default:
			// æ£€æŸ¥è¯·æ±‚æ•°é™åˆ¶
			if totalRequests > 0 && requestCount >= int64(totalRequests) {
				return
			}

			// é€Ÿç‡é™åˆ¶
			if b.rateLimiter != nil {
				b.rateLimiter.Wait(ctx)
			}

			select {
			case requestChan <- struct{}{}:
				requestCount++
			case <-ctx.Done():
				return
			}
		}
	}
}

// executeRequest æ‰§è¡Œå•ä¸ªè¯·æ±‚
func (b *Benchmark) executeRequest(ctx context.Context, workerID int) {
	startTime := time.Now()

	// åˆ›å»ºè¯·æ±‚
	req, err := b.createRequest(ctx, workerID)
	if err != nil {
		b.stats.RecordError("request_creation", err)
		fmt.Printf("err: %e \n", err)
		return
	}

	// å‘é€è¯·æ±‚
	resp, err := b.client.Do(req)
	latency := time.Since(startTime)

	if err != nil {
		b.stats.RecordError("network", err)
		fmt.Printf("err: %e \n", err)
		b.stats.RecordRequest(latency, 0, 0, false)
		return
	}
	defer resp.Body.Close()

	// è¯»å–å“åº”ä½“
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		b.stats.RecordError("body_read", err)
		fmt.Printf("err: %e \n", err)
		b.stats.RecordRequest(latency, 0, 0, false)
		return
	}

	// éªŒè¯å“åº”
	validationErr := b.validator.Validate(resp, body)
	success := validationErr == nil

	if !success {
		b.stats.RecordError("validation", validationErr)
		fmt.Printf("err: %e \n", validationErr)
	}

	// è®°å½•ç»Ÿè®¡
	b.stats.RecordRequest(latency, int64(len(body)), int64(req.ContentLength), success)
	b.stats.RecordStatusCode(resp.StatusCode)
}

// createRequest åˆ›å»ºHTTPè¯·æ±‚
func (b *Benchmark) createRequest(ctx context.Context, workerID int) (*http.Request, error) {
	// åº”ç”¨æ¨¡æ¿
	url := b.config.Target.URL
	body := b.config.Target.Body

	if b.config.Request.Template.Enabled {
		vars := map[string]interface{}{
			"worker_id": workerID,
			"timestamp": time.Now().Unix(),
		}

		var err error
		url, err = b.template.Render(url, vars)
		if err != nil {
			return nil, fmt.Errorf("æ¸²æŸ“URLæ¨¡æ¿å¤±è´¥: %w", err)
		}

		if b.config.Request.DynamicBody {
			body, err = b.template.Render(b.config.Request.BodyTemplate, vars)
			if err != nil {
				return nil, fmt.Errorf("æ¸²æŸ“Bodyæ¨¡æ¿å¤±è´¥: %w", err)
			}
		}
	}

	// åˆ›å»ºè¯·æ±‚
	var req *http.Request
	var err error

	if body != "" {
		req, err = http.NewRequestWithContext(ctx, b.config.Target.Method, url,
			strings.NewReader(body))
	} else {
		req, err = http.NewRequestWithContext(ctx, b.config.Target.Method, url, nil)
	}

	if err != nil {
		fmt.Printf("err: %e\n", err)
		return nil, err
	}

	// è®¾ç½®è¯·æ±‚å¤´
	for key, value := range b.config.Target.Headers {
		req.Header.Set(key, value)
	}
	for key, value := range b.config.Request.Headers {
		req.Header.Set(key, value)
	}

	// è®¾ç½®Cookie
	for _, cookie := range b.config.Request.Cookies {
		req.AddCookie(&http.Cookie{
			Name:     cookie.Name,
			Value:    cookie.Value,
			Domain:   cookie.Domain,
			Path:     cookie.Path,
			Expires:  cookie.Expires,
			Secure:   cookie.Secure,
			HttpOnly: cookie.HttpOnly,
		})
	}

	return req, nil
}

// Close å…³é—­åŸºå‡†æµ‹è¯•å™¨
func (b *Benchmark) Close() error {
	b.running.Store(false)
	return nil
}

// createHTTPClient åˆ›å»ºHTTPå®¢æˆ·ç«¯
func createHTTPClient(cfg *config.Config) (*http.Client, error) {
	// TLSé…ç½®
	tlsConfig, err := createTLSConfig(cfg.TLS)
	if err != nil {
		return nil, err
	}

	// HTTP/3 (QUIC)
	if cfg.Protocol.HTTP3Enabled {
		return &http.Client{
			Transport: &http3.RoundTripper{
				TLSClientConfig: tlsConfig,
			},
			Timeout: cfg.Target.Timeout,
		}, nil
	}

	// HTTP/1.1 å’Œ HTTP/2
	transport := &http.Transport{
		TLSClientConfig:     tlsConfig,
		MaxIdleConns:        cfg.Load.Concurrency * 2,
		MaxIdleConnsPerHost: cfg.Load.Concurrency,
		IdleConnTimeout:     cfg.Protocol.IdleTimeout,
		DisableKeepAlives:   !cfg.Protocol.KeepAlive,
	}

	// HTTP/2
	if cfg.Protocol.HTTP2Enabled {
		http2.ConfigureTransport(transport)
	}

	return &http.Client{
		Transport: transport,
		Timeout:   cfg.Target.Timeout,
	}, nil
}

// createTLSConfig åˆ›å»ºTLSé…ç½®
func createTLSConfig(cfg config.TLSConfig) (*tls.Config, error) {
	if !cfg.Enabled {
		return nil, nil
	}

	tlsConfig := &tls.Config{
		InsecureSkipVerify: cfg.InsecureSkipVerify,
	}

	// TLSç‰ˆæœ¬
	switch cfg.MinVersion {
	case "TLS1.0":
		tlsConfig.MinVersion = tls.VersionTLS10
	case "TLS1.1":
		tlsConfig.MinVersion = tls.VersionTLS11
	case "TLS1.2":
		tlsConfig.MinVersion = tls.VersionTLS12
	case "TLS1.3":
		tlsConfig.MinVersion = tls.VersionTLS13
	default:
		tlsConfig.MinVersion = tls.VersionTLS12
	}

	switch cfg.MaxVersion {
	case "TLS1.2":
		tlsConfig.MaxVersion = tls.VersionTLS12
	case "TLS1.3":
		tlsConfig.MaxVersion = tls.VersionTLS13
	}

	// å®¢æˆ·ç«¯è¯ä¹¦(åŒå‘è®¤è¯)
	if cfg.MutualTLS && cfg.ClientCertFile != "" && cfg.ClientKeyFile != "" {
		cert, err := tls.LoadX509KeyPair(cfg.ClientCertFile, cfg.ClientKeyFile)
		if err != nil {
			return nil, fmt.Errorf("åŠ è½½å®¢æˆ·ç«¯è¯ä¹¦å¤±è´¥: %w", err)
		}
		tlsConfig.Certificates = []tls.Certificate{cert}
	}

	return tlsConfig, nil
}

// ç»§ç»­å®ç°å‰©ä½™æ–¹æ³•...
